<!DOCTYPE html>
<html>

  <head>
    <meta charset='utf-8'>
    <meta http-equiv="X-UA-Compatible" content="chrome=1">
    <meta name="description" content="haiyangliu.me">  

   	<link rel="stylesheet" type="text/css" media="screen" href="stylesheets/stylesheet.css">
	<link href="http://fonts.googleapis.com/css?family=Ubuntu" rel="stylesheet" type="text/css" />
	<link href="http://fonts.googleapis.com/css?family=Abel" rel="stylesheet" type="text/css" />
	<link href="http://fonts.googleapis.com/css?family=Lobster" rel="stylesheet" type="text/css" />
	<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.6.3/css/font-awesome.min.css">
	<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.2.1/css/all.min.css">
	<link rel="stylesheet" type="text/css" href="style.css" />

    <title>Haiyang Liu - About Me</title>
    <link rel="icon" type="image/x-icon" href="favicon.ico">
    <link rel="shortcut icon" type="image/x-icon" href="favicon.ico">
  </head>

  <body>

    <!-- HEADER -->
    <div id="header_wrap" class="outer">
        <header class="inner">

	</header>
    </div>

    <!-- MAIN CONTENT -->
    <div id="main_content_wrap" class="outer">
      <section id="main_content" class="inner">
 
    <table border="0">
	<tbody>
		<tr>
		<td width="220">
			<img src=".\images\xxx.jpg" border="0" width="170">
		</td>
		<td width="560">
			<div>					
				<h3>Haiyang Liu </h3>
			</div>
			<p>
			            Ph.D. Candidate
				<br>Graduate School of Information Science and Technology,
				<br>The University of Tokyo
				<br></i>liuhaiyang<i class="fa fa-at" aria-hidden="true"></i>kmj.iis.u-tokyo.ac.jp
				<br> 
				<a href="www.linkedin.com/in/haiyang-liu-244179193"><i class="fa-brands fa-linkedin" style="color:dodgerblue"></i></a>
				<a href="https://github.com/H-Liu1997"><i class="fa-brands fa-github-alt" style="color:black" aria-hidden="true"></i></a> 
<!--				<a href="https://scholar.google.com/citations?user=U_9vNgsAAAAJ&hl=zh-CN"><i class="fa fa-graduation-cap" style="color:mediumseagreen" aria-hidden="true"></i></a> -->
				<a href="https://space.bilibili.com/524111667/"><i class="fa-brands fa-bilibili" style="color:palevioletred"></i></a>
				
			</p>
		</td>
		<tr>
	</tbody>
</table>     

      <h3>Biography</h3>
<p>I am a Ph.D. candidate in the <a href="http://kmj.iis.u-tokyo.ac.jp/e_index.html" style="color:gray">Kamijo Lab</a>, Graduate School of Information Science and Technology, The University of Tokyo, supervised by Prof. 
	<a href="https://scholar.google.co.jp/citations?user=CLxG_zgAAAAJ&hl=en" style="color:gray">Shunsuke Kamijo</a>. 
	I am working on deep learning based generation model for cross-modal mapping, <em>e.g.</em>, gestures and audio.

	I received my M.E. from Waseda Universiy, supervised by Prof. <a href="https://scholar.google.com/citations?user=Q2ugsNcAAAAJ&hl=ja" style="color:gray">Takeshi Ikenaga</a>, in 2020, and B.E. from Southeast Universiy (China), in 2019.
	<br> I prefer and respect simple and effective ideas, <em>e.g.</em>, <a href="https://arxiv.org/abs/1611.05424" style="color:gray">Associative Embedding</a>, <a href="https://dl.acm.org/doi/10.1145/3528223.3530178" style="color:gray">Motion Manifolds</a>. I'm also interested and open for collaboration in content generation of the digital twins, virtual Youtuber and game NPC, <em>etc</em>.    
	</p>
      
	      
      <!-- <h3>News</h3>      
	<div>
		<ul>
			<li>Topic: Real-time 3D Deformation Matching System</li>
		</ul>
	</div>  -->

	  <h3>Research Interests</h3>      
	<div>
		<ul>
			<li>Generation Model</li>
			<li>Cross-Modal Mapping</li>
			<li>Human Pose and Gestures</li>			
		</ul>
	</div>     	

	      
      <h3>Research Achievements</h3>      
	<div>
		<ul>		
			<li><u>Haiyang Liu</u>, Zihao Zhu, Naoya Iwamoto, Yichen Peng, Zhengqing Li, You Zhou, Elif Bozkurt and Bo Zheng, 
				<a href="https://pantomatrix.github.io/BEAT/" style="color:black">“BEAT: A Large-Scale Semantic and Emotional Multi-Modal Dataset for Conversational Gestures Synthesis,”</a> 
				European Conference on Computer Vision (ECCV), 2022.</p></li>
			<li><u>Haiyang Liu</u>, Naoya Iwamoto, Zihao Zhu, Zhengqing Li, You Zhou, Elif Bozkurt and Bo Zheng, 
				<a href="https://pantomatrix.github.io/DisCo/" style="color:black">“DisCo: Disentangled Implicit Content and Rhythm Learning for Diverse Co-Speech Gesture Synthesis,”</a> 
				ACM International Conference on Multimedia (ACM MM), 2022.</p></li>
			<li><u>Haiyang Liu</u> and Jihan Zhang, “Improving Ultrasound Tongue Image Reconstruction from Lip Images Using Self-supervised Learning and Attention Mechanism,” ACM SIGKDD Conference on Knowledge Discovery and Data Mining Workshop (KDDW), 2021.</p></li>
			<li><u>Haiyang Liu</u> and Jihan Zhang, “Reinforcement Learning based Neural Architecture Search for Audio Tagging,” International Joint Conference on Neural Networks (IJCNN), 2020.</p></li>
			<li><u>Haiyang Liu</u>, Dingli Luo, Songlin Du, Takeshi Ikenaga, “Resolution Irrelevant Encoding and Difficulty Balanced Loss Based Network Independent Supervision for Multi-Person Pose Estimation,” International Conference on Human System Interaction (HSI), 2020.</p></li>
		</ul>
       </div>
      
	      
      <h3>Intern Experience</h3>      
	<div>
		<ul>
			<li>(2020.11 - ) Digital Human Lab, Huawei Tokyo Research Center. 
				Major Topic: Co-Speech Gestures Generation. Mentor: Naoya Iwamoto, Bo Zheng.</li>
		</ul>
	</div>
	
	   <h3>Academic Services</h3>      
	<div>
		<ul>
			<li>Invited Talk: To Visual Computing 2022, Kotyo, Japan, 2022.10.</li>
			<li>Invited Talk: To TechBeat, Beijing, China, 2023.02.</li>
			<li>PC: International Conference on AIGC, Shanghai, China, 2023.03.</li>
		</ul>
	</div>

      </section>
    </div>

    <!-- FOOTER  -->
    <div id="footer_wrap" class="outer">
      <footer class="inner">
      
      </footer>
    </div>

    

  </body>
</html>
